# configs/trainer/default.yaml

init:
  _target_: pytorch_lightning.Trainer
  max_epochs: 1000
  accelerator: "auto"
  devices: 1
  precision: "bf16-mixed"
  accumulate_grad_batches: 1
  log_every_n_steps: 35
  check_val_every_n_epoch: 1
  enable_checkpointing: true
  enable_progress_bar: true
  enable_model_summary: true
  deterministic: false
  benchmark: false
  
  
  callbacks:
    - _target_: pytorch_lightning.callbacks.ModelCheckpoint
      monitor: "val/roc_auc"
      mode: "max"
      save_top_k: 1         
      save_last: false      
      filename: "best"
      auto_insert_metric_name: false
      
    - _target_: pytorch_lightning.callbacks.ModelCheckpoint
      save_top_k: 0         
      save_last: true       
      filename: "last"      
      verbose: false
      
    - _target_: pytorch_lightning.callbacks.LearningRateMonitor
      logging_interval: "epoch"

    - _target_: pytorch_lightning.callbacks.EarlyStopping
      monitor: "val/roc_auc"
      patience: 50
      mode: "max"



