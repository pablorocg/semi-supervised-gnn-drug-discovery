# configs/trainer/hpo.yaml

init:
  _target_: pytorch_lightning.Trainer
  max_epochs: 250
  accelerator: "auto"
  devices: 1
  precision: "bf16-mixed"
  accumulate_grad_batches: 1
  log_every_n_steps: 20
  check_val_every_n_epoch: 1
  enable_checkpointing: true
  enable_progress_bar: true
  enable_model_summary: true
  deterministic: false
  benchmark: true
  